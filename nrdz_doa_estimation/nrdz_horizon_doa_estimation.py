# This script uses both the maximum likelihood and MVDR algorithm to estimate the direction of arrival (DOA)
# Read the data from file or use test data generated by script
# Perform an FFT first
# Calculate sample covariance matrix for each frequency channel
# Estimate coordinates with minimum result from maximum likelihood output
# And estimate coordinates with maximum result from MVDR output for comparison in performance
# Specifically analysis of the horizon (90 degree elevation, azimuth cut)

import os
import sys
import time
import math
import numpy as np
import matplotlib.pyplot as plt
from numpy.linalg import matrix_rank
from scipy import fftpack

# Size of real/imaginary data in file
#data_size = 20000000 # Large data size similar to real data
data_size = 2000 # Small data size for quick testing so you don't sit around waiting forever 
# Speed of light
c = 3e8
n_sources = 1 # Number of sources
src1_el = 90 #45 # First source's elevation
src1_az = 225 # First source's azimuth
ang_spread_el = 0 # 0.09 # The angle spread between sources in elevation
ang_spread_az = 35 # 0.09 # The angle spread between sources in azimuth
deg_range = 10000 # Number of coordinates being scanned/analyzed/plotted

ant_center_freq = 1e3 # 1e5
ant_freq = 1e3+1e6 # 1e5+1e6 # Frequency of signal (one of them if there are multiple at different frequencies) being detected
ant_f_down = 0 #1e3 # Shift frequency down if signal frequency is high and baselines are very long
samp_rate = 20e6 #20e6 # Sample rate of synthesized signal
n_points = 100 # Number of points of FFT
tbin = 1/samp_rate # Time between samples
full_band = samp_rate #20e6 # Full bandwidth in Hz
coarse_chan = full_band/n_points

radio_interferomters = ["NRDZ-sensors", "ATA"] # Show these options in help command
array_conf = radio_interferomters[0] # Input from User. 

center_el = 90 # Center elevation of map/field of view
center_az = 180 # Center azimuth of map/field of view
half_range = 180 # Half of the full range of coordinates on an axis
min_el = center_el - (half_range/4) # Minimum elevation along axis
max_el = center_el + (half_range/4) # Maximum elevation along axis
el_interval = (max_el-min_el)/(deg_range-1) # Interval between neighboring elevation coordinates. The minus 1 in the denominator is to accomodate the way linspace calculates the interval
min_az = center_az - half_range # Minimum azimuth along axis
max_az = center_az + half_range # Maximum azimuth along axis
az_interval = (max_az-min_az)/(deg_range-1) # Interval between neighboring azimuth coordinates. The minus 1 in the denominator is to accomodate the way linspace calculates the interval

# File path
#filepath = "/mnt/primary-1G/test/"
#filepath = "/home/sonata/src/nrdz_toolkit/nrdz_doa_estimation/output/"
filepath = "/mnt/local_data/nrdz_test/"
# Extension of files
extension = ".sc16"


def parabolic_reflector_radiation_pattern(diameter, wavelength, azimuth, elevation):
    A = np.sinc((np.pi*diameter*np.sin(azimuth*np.pi/180)*np.cos(elevation*np.pi/180)/wavelength))
    
    return A

if array_conf == radio_interferomters[0]:
    ant_pattern = lambda ant_wavelength: 10 # Isotropic antenna

    reference_ant = {"north": [40.8216550, -121.4682424]}

    antennas = {"rooftop": [40.8172, -121.469], 
    "gate": [40.8257948, -121.4702578], 
    "chime": [40.8166504, -121.4639321], 
    "west": [40.8167476, -121.4720492], 
    "nuevo": [40.8242, -121.4700]}

elif array_conf == radio_interferomters[1]:
    ant_diameter = 6.1
    #ant_wavelength = c/ant_freq
    ant_elevation = 0
    ant_azimuth = 90
    ant_pattern = lambda ant_wavelength: parabolic_reflector_radiation_pattern(ant_diameter, ant_wavelength, ant_azimuth, ant_elevation)
    
    reference_ant = {"1a": [40.816712869598824, -121.47104786441923]}
    
    antennas = {"1b": [40.81656164962182, -121.47064246433446],
    "1c": [40.81598672956708, -121.47073316425822],
    "1d": [40.816020919548556, -121.47101366431262],
    "1e": [40.816118279542216, -121.47118336435452],
    "1f": [40.81610954951161, -121.47153176440668],
    "1g": [40.81629270952532, -121.47153856443505],
    "1h": [40.81642770951056, -121.47183376450059],
    "1j": [40.81683078953103, -121.47195666457858],
    "1k": [40.816714109574605, -121.47133636446472],
    "2a": [40.81743072968048, -121.47073476447545],
    "2b": [40.81733629969617, -121.47046306441914],
    "2c": [40.81708831967276, -121.47051706439166],
    "2d": [40.81689592969735, -121.4700501642903],
    "2e": [40.81692103971665, -121.46984496426194],
    "2f": [40.8170445795826, -121.4715439645459],
    "2g": [40.81702735955206, -121.47188836459696],
    "2h": [40.81713778956801, -121.47180126459976],
    "2j": [40.81727308959045, -121.47165746459687],
    "2k": [40.81732482960396, -121.47154386458651],
    "2l": [40.817330509629556, -121.47124826454152],
    "2m": [40.81731489966026, -121.47087376448117],
    "3c": [40.817723089775875, -121.46987526438447],
    "3d": [40.81792499974508, -121.47042396449997],
    "3e": [40.81782593971099, -121.47073826453484],
    "3f": [40.817715489686485, -121.47092576454763],
    "3g": [40.81769358967525, -121.4710387645621],
    "3h": [40.81777863968334, -121.47100596456677],
    "3j": [40.81812358976585, -121.47035936451907],
    "3l": [40.81830225975086, -121.47070116459905],
    "4e": [40.8179877798225, -121.4695646643747],
    "4f": [40.81815999978997, -121.47010756448512],
    "4g": [40.818336179775734, -121.47043646456237],
    "4h": [40.8183644197648, -121.47059216459104],
    "4j": [40.818545549820264, -121.47009796453975],
    "4k": [40.81831159981528, -121.46994726448243],
    "4l": [40.8183095098262, -121.4698188644626],
    "5b": [40.8182326298965, -121.46891176430843],
    "5c": [40.81807838989098, -121.46883596427385],
    "5e": [40.81800398989564, -121.46871006424269],
    "5g": [40.817955419865314, -121.46902806428588],
    "5h": [40.818073009877175, -121.468994864298]}


ref_ant_name = list(reference_ant.keys())
antenna_names = list(antennas.keys())
#print(antennas[antenna_names[0]][0])

# Number of antennas
n_ants = len(antenna_names)+1


def coordinate_calculation(ref_lat, ant_lat, deltaLat, deltaLng):
    xy_coords = {}
    
    # Calculate distance between points
    R = 6371e3 # Radius of the earth in meters
    for ant in range(0,len(antenna_names)):
        a = np.sin(deltaLat[ant]/2)*np.sin(deltaLat[ant]/2) + np.cos(ant_lat[ant])*np.cos(ref_lat)*np.sin(deltaLng[ant]/2)*np.sin(deltaLng[ant]/2)
        c = 2*np.arctan2(np.sqrt(a),np.sqrt(1-a))
        d = R*c

        # Calculate bearing
        y_bearing = np.sin(deltaLng[ant])*np.cos(ref_lat)
        x_bearing = np.cos(ant_lat[ant])*np.sin(ref_lat) - np.sin(ant_lat[ant])*np.cos(ref_lat)*np.cos(deltaLng[ant])
        theta = np.arctan2(y_bearing, x_bearing)
        bearing = theta*180/np.pi

        # Calculate x and y coordinates between reference and other antenna in meters
        x = d*np.sin(theta)
        y = d*np.cos(theta)
        
        # Store x and y baseline in dictionary
        lat = antennas[antenna_names[ant]][0]
        lng = antennas[antenna_names[ant]][1]
        xy_coords[antenna_names[ant],lat,lng] = [x, y]
    
    return xy_coords

def cartesian_estimates():
    # Reference antenna
    ref_lat = reference_ant[ref_ant_name[0]][0]*np.pi/180
    ref_lng = reference_ant[ref_ant_name[0]][1]*np.pi/180

    # Antenna
    ant_lat = [antennas[ant][0]*np.pi/180 for ant in antenna_names]
    ant_lng = [antennas[ant][1]*np.pi/180 for ant in antenna_names]

    # Change in latitude and longitude of reference antenna and other
    deltaLat = [ref_lat - ant_lat[l] for l in range(0,len(ant_lat))]
    deltaLng = [ref_lng - ant_lng[l] for l in range(0,len(ant_lng))]

    # x and y coordinate estimates
    xy_coords = {}
    xy_coords[ref_ant_name[0],reference_ant[ref_ant_name[0]][0],reference_ant[ref_ant_name[0]][1]] = [0,0]
    xy_coords.update(coordinate_calculation(ref_lat, ant_lat, deltaLat, deltaLng))
    
    return xy_coords

# Generate synthetic data
def synthetic_data(sim_freq, tbin, rx, ry, rz):
    x_comp = np.zeros([data_size], dtype=complex) # Complex data array
    w = 2*np.pi*sim_freq # Angular frequency
    s = np.zeros([data_size, n_sources], dtype=complex) # Signal amplitude
    #a = np.zeros([n_sources]) + 1j*np.zeros([n_sources]) # Array steering vector
    el = np.zeros([data_size, n_sources]) # Elevation over time and of each source
    az = np.zeros([data_size, n_sources]) # Azimuth over time and of each source
    samp_el_offset = 0 # Change in elevation over time. Offsets signal position with a change in sample
    samp_az_offset = 0 # Change in azimuth over time. Offsets signal position with a change in sample
     
    #noise = np.random.normal(loc=0, scale=0.000000001, size=data_size, dtype=complex)
    noise = np.random.normal(loc=0, scale=1, size=data_size) + 1j*np.random.normal(loc=0, scale=1, size=data_size)
    srcs = 0
    hpbw = 1
    A = 10
    second_sig_freq = 0 #200e3
    for t in range(0, data_size):
        srcs = 0
        prev_srcs = 0
        for p in range(0, n_sources):
            # Calculate el and az for each time sample of each source
            el[t,p] = (src1_el + (ang_spread_el*p) + samp_el_offset*t)*np.pi/180
            az[t,p] = (src1_az + (ang_spread_az*p) + samp_az_offset*t)*np.pi/180
            # Calculate ideal array steering vector using the array_manifold_vector() function
            if p == 0:
                w = 2*np.pi*sim_freq
            elif p == 1:
                w = 2*np.pi*(sim_freq+second_sig_freq)
            phase = (-1*w/c)*(\
            rx*np.sin(el[t,p])*np.cos(az[t,p])\
            + ry*np.sin(el[t,p])*np.sin(az[t,p])\
            + rz*np.cos(el[t,p]))
            #s[t,p] = np.exp(1j*((w*t*tbin) + (phase%(2*np.pi))))
            s[t,p] = np.exp(1j*((w*t*tbin) + (phase)))
            #s[t,p] = np.sinc(sim_freq*t*tbin)*np.exp(1j*phase)
            # ------------------Add noise---------------
            #A = np.exp(-2*(np.log(2)*pow(el[t,p],2)/pow(hpbw,2)))
            # Sum all source signals
            #if p == 0:
            #    A = 10
            #elif p > 0:
            #    A = 10
            ant_lambda = c/sim_freq
            A = ant_pattern(ant_lambda)
            srcs += A*s[t,p]
            
        # Assign srcs to signal vector
        #x_comp[t] = srcs + noise[t]
        x_comp[t] = srcs
        
    x_comp += noise
        
    # Check if signals are linearly independent
    #is_linearly_independent = np.all(np.linalg.det(np.vstack((s[0,:],s[1,:])).T) != 0)
    #print("Are the signals linearly independent? ", is_linearly_independent)

    return x_comp

# Generate synthetic data and write to binary file to test the code
def write_synthetic_data(filename, sim_freq, tbin, rx, ry, rz, n_ants):
    x_comp = np.zeros([n_ants, data_size], dtype=complex) # Complex data array
    x = np.zeros([2*data_size]).astype(np.int16) # Interleaved data array (real - even, imag - odd)
    full_filename = [""]*n_ants
    file_count = 0 # Count number of files generated
    
    # Generate synthetic data
    for i in range(0, n_ants):
        full_filename[i] = filepath + filename + str(i) + extension
        if not os.path.exists(full_filename[i]):
            x_comp[i,:] = synthetic_data(sim_freq, tbin, rx[i], ry[i], rz[i])
            file_count += 1
        else:
            print("Test file, " + full_filename[i] + " exists so don't need to synthesize data, create, and write to it again.")
        
    # Convert elements in array to 16 bit integers the same way as with live data acquisition
    if file_count > 0:
        # Determine the maximum absolute value of the real and imaginary arrays
        max_int16 = 32767
        max_abs_value = np.max(np.abs(x_comp))
        scaling_factor = max_int16/max_abs_value
        scaled_x_comp = scaling_factor*x_comp
        arr_r = np.array(scaled_x_comp.real)
        scaled_arr_r = (arr_r).astype(np.int16)
        arr_i = np.array(scaled_x_comp.imag)
        scaled_arr_i = (arr_i).astype(np.int16)
    else:
        print("No conversion to 16 bits needed since no file need to be written.")
    
    for i in range(0, n_ants):
        if not os.path.exists(full_filename[i]):
            # Interleave real and imaginary components in array
            x[0:(2*data_size):2] = scaled_arr_r[i,:]
            x[1:(2*data_size):2] = scaled_arr_i[i,:]
            
            # Write data to binary file
            print("Writing to file, " + full_filename[i])
            with open(full_filename[i], 'wb') as f:
                f.write(x.tobytes())
            f.close()
        else:
            print(full_filename[i] + " exists.")

# Read file or generate test data 
def complex_data_sc16(data_flag, sim_freq, tbin, filename, rx, ry, rz):
    if data_flag == 0: # Use test data
        data_comp = synthetic_data(sim_freq, tbin, rx, ry, rz)
    elif data_flag == 1: # Read binary file
        if os.path.exists(filename):
            with open(filename, 'rb') as f:
                contents_nrdz = np.fromfile(f, dtype=np.int16)
                contents_size = len(contents_nrdz)
                # Interleave inphase and quadrature
                data_re = contents_nrdz[0:contents_size:2]
                data_im = contents_nrdz[1:contents_size:2]
                data_comp = data_re + 1j*data_im
        else:
            print("File, " + filename + " does not exist. Try another file.")
            print("Exiting...")
            sys.exit()
            
        f.close()
        
    return data_comp

# Perform FFT and return 2D array with dimensions, NSAMPS X NPOINTS
def perform_FFT(complex_data, n_points):
    data_len = len(complex_data)
    n_samps = int(data_len/n_points)
    data_fft = np.zeros([n_samps, n_points], dtype=complex) 
    # Perform N-point FFT on data with dimensions, NSAMPS x NPOINTS
    for i in range(0, n_samps):
        data_fft[i,:] = np.fft.fftshift(np.fft.fft(complex_data[(0+i*n_points):(n_points+i*n_points)]))
        #data_fft[i,:] = (np.fft.fft(complex_data[(0+i*n_points):(n_points+i*n_points)]))
    
    return data_fft 

# Estimate visibilities (cross correlations)
def estimate_visibilities(x, n_ants, n_samps):
    vis = np.asarray([np.multiply(x[n,:],np.conj(x[m,:])) for n in range(0, n_ants) for m in range(0, n_ants) if n!=m])
    #print("Visibility shape = " + str(np.shape(vis)))
    
    return vis
    
# Estimate auto correlations
def estimate_auto_correlations(x, n_ants, n_samps):
    autos = np.asarray([np.multiply(x[n,:],np.conj(x[m,:])) for n in range(0, n_ants) for m in range(0, n_ants) if n==m])
    #print("Autos shape = " + str(np.shape(autos)))
    
    return autos

# Calculate phase shift to use in synthesis imaging
def interferometric_phase_shift(elevation, azimuth, rx, ry, rz, f, n_ants):
    # Angular frequency
    w = 2*np.pi*f
    #el = (src1_el-half_range + el_interval*elevation)*np.pi/180
    #az = (src1_az-half_range + az_interval*azimuth)*np.pi/180
    
    el = elevation*np.pi/180
    az = azimuth*np.pi/180
    
    if n_ants == 1:
        sys.exit("You have to set more than one antenna")
    else:
        a = np.asarray([np.exp((-1j*w/c)*(((rx[m]-rx[n])*np.sin(el)*np.cos(az) + (ry[m]-ry[n])*np.sin(el)*np.sin(az) + (rz[m]-rz[n])*np.cos(el)))) for n in range(0,n_ants) for m in range(0,n_ants) if n!=m])
    
    #print("Phase shift vector shape = " + str(np.shape(a)))
    
    return a

# Estimate sample covariance
#def estimate_sample_covariance(x, n_ants, n_samps, n_points, n_ints):
#    n_windows = int(n_samps/n_ints)
#    if n_points > 1:
#        R_est = np.zeros([n_ants, n_ants, n_samps, n_points], dtype=complex)
#        R_hat = np.zeros([n_ants, n_ants, n_windows, n_points], dtype=complex)
#    # Estimate covariance
#    #for a in range(0, n_ants):
#    #    for b in range(0, n_ants):
#    #        R_est[a,b,:,:] = (np.multiply(x[a,:,:], np.conjugate(x[b,:,:])))
#            
#        for f in range(0, n_points):
#            for t in range(0, n_samps):
#                x_H = np.transpose(np.conj(x[:,t,f]))
#                R_est[:,:,t,f] = (np.outer(x[:,t,f], x_H))
            
#        # Integrate over time samples
#        for i in range(0, n_windows):
#            R_hat[:,:,i,:] = (1/n_ints)*np.sum(R_est[:,:,(0 + i*n_ints):((n_ints + i*n_ints)),:], axis=2)
#    elif n_points == 1:
#        R_est = np.zeros([n_ants, n_ants, n_samps], dtype=complex)
#        R_hat = np.zeros([n_ants, n_ants, n_windows], dtype=complex)

#        for t in range(0, n_samps):
#            x_H = np.transpose(np.conj(x[:,t]))
#            R_est[:,:,t] = (np.outer(x[:,t], x_H))
            
#        # Integrate over time samples
#        for i in range(0, n_windows):
#            R_hat[:,:,i] = (1/n_ints)*np.sum(R_est[:,:,(0 + i*n_ints):((n_ints + i*n_ints))], axis=2)
            
#    return R_hat
    
# Estimate sample covariance
def estimate_sample_covariance(x, n_ants, n_samps, n_points, n_ints):
    n_windows = int(n_samps/n_ints)
    if n_points > 1:
        R_est = np.zeros([n_ants, n_ants, n_samps], dtype=complex)
        R_hat = np.zeros([n_ants, n_ants, n_windows], dtype=complex)
        
        for t in range(0, n_samps):
            x_H = np.transpose(np.conj(x[:,t]))
            R_est[:,:,t] = (np.outer(x[:,t], x_H))
            
        # Integrate over time samples
        for i in range(0, n_windows):
            R_hat[:,:,i] = (1/n_ints)*np.sum(R_est[:,:,(0 + i*n_ints):((n_ints + i*n_ints))], axis=2)
    elif n_points == 1:
        R_est = np.zeros([n_ants, n_ants, n_samps], dtype=complex)
        R_hat = np.zeros([n_ants, n_ants, n_windows], dtype=complex)

        for t in range(0, n_samps):
            x_H = np.transpose(np.conj(x[:,t]))
            R_est[:,:,t] = (np.outer(x[:,t], x_H))
            
        # Integrate over time samples
        for i in range(0, n_windows):
            R_hat[:,:,i] = (1/n_ints)*np.sum(R_est[:,:,(0 + i*n_ints):((n_ints + i*n_ints))], axis=2)

    return R_hat
    
# Calculate array manifold vector to use in MVDR solution
def array_manifold_vector(elevation, azimuth, rx, ry, rz, f, n_ants, mix_down, t):
    # Angular frequency
    w = 2*np.pi*f
    w_shift = 2*np.pi*ant_f_down
    
    el = elevation*np.pi/180
    az = azimuth*np.pi/180
    
    a = np.zeros([n_ants,1], dtype=complex)
    
    # I believe I need to add the phase correction here
    # The phase added to remove the fringe function does not need to be added when live data or simulated earth rotation is NOT being read
    # But if earth is assumed to be rotating, the fringe function can be removed by adding a geometric delay to shift back to phase center by
    #    tau_geo = 
    #    where w_e = 7.3e-5 rad/s which is the angular rotation frequency of the earth
    # For the NRDZ sensors, the phase center cannot be chosen since they cannot be electronically steered. They are at fixed positions
    
    if n_ants == 1:
        sys.exit("You have to set more than one antenna")
    else:
        for i in  range(0,n_ants):
            if mix_down == 0:
                a[i] = np.exp((-1j*(w-w_shift)/c)*((rx[i]*np.sin(el)*np.cos(az) + ry[i]*np.sin(el)*np.sin(az) + rz[i]*np.cos(el))))
            elif mix_down == 1:
                a[i] = np.exp((1j*w_shift)*(((1/c)*(rx[i]*np.sin(el)*np.cos(az) + ry[i]*np.sin(el)*np.sin(az) + rz[i]*np.cos(el)) - (t*tbin))))
    
    return a

# Frequency shift. Mix signal down given longer baselines
def mix_signal_down(x, az, el, rx, ry, rz, f, ch, n_ants, n_samps):
    a = np.zeros([n_ants,1], dtype=complex)
    w = 2*np.pi*f
    mix_down = 1
    
    x_tmp = x[:,:,ch]
    
    x_shift = np.zeros([n_ants,n_samps],dtype=complex)
    for t in range(0,n_samps):
        a = array_manifold_vector(el, az, rx, ry, rz, f, n_ants, mix_down, t)
        x_shift[:,t] = a.flatten()*x_tmp[:,t]
    
    return x_shift

def main():
    start_time = time.time()
    center_freq = ant_center_freq
    freq = ant_freq # Frequency of signal (one of them if there are multiple at different frequencies) being detected
    #center_freq = 1e3
    #chan_idx = 50 # Narrowband frequency channe index - typically arbitrarily chosen to be at center of bandwidth
    narrowband_freqs = np.zeros([n_points,1])
    for ch in range(0, n_points):
        if n_points > 1:
            f = center_freq + (ch-n_points/2)*coarse_chan
            narrowband_freqs[ch] = f
        elif n_points == 1:
            f = center_freq
    chan_idx = np.where(abs(narrowband_freqs-freq)==min(abs(narrowband_freqs-freq)))[0] # Narrowband frequency channel index
    print("Channel index = " + str(chan_idx[0]) + " of " + str(n_points))
    if data_size == 20000000:
        n_ints = 100 # Number of time samples to integrate
    elif data_size == 2000:
        if n_points == 1000:
            n_ints = 2
        elif n_points == 500:
            n_ints = 4
        elif n_points == 100:
            n_ints = 20 # Number of time samples to integrate
        elif n_points == 1:
            n_ints = 100
    else:
        n_ints = 1 # Number of time samples to integrate
    n_samps = int(data_size/n_points) # Number of time samples after FFT
    
    print("Calculating cartesian coordiantes...")

    # x and y coordinate estimates
    ant_rect_coords = {}
    ant_rect_coords = cartesian_estimates()
    
    # Store cartesian estimates
    rx = np.zeros(n_ants)
    ry = np.zeros(n_ants)
    rz = np.zeros(n_ants)
    rx = np.asarray([ant_rect_coords[xy][0] for xy in ant_rect_coords])
    ry = np.asarray([ant_rect_coords[xy][1] for xy in ant_rect_coords])
    
    data_flag = 0 # If set to 0, the script generates it's own data, and if set to 1, it reads a file
    sim_data_write = 1 # If set to 1, the script synthesizes data and writes it to a binary file to be read, and if set to 0, the simulated data is not written to and read from binary files
    
    filename = "sensor_test_"
    full_filename = [""]*n_ants
    
    # Synthesize test data if flag is set to 1
    if sim_data_write == 1:
        print("Writing data to files...")
        data_flag = 1
        write_synthetic_data(filename, freq, tbin, rx, ry, rz, n_ants)
    else:
        print("Simulated data has not been written to any files. It has just been generated and processed by the script.")
    
    print("Reading data for processing...")
    if n_points > 1:
        X_agg = np.zeros([n_ants, n_samps, n_points], dtype=complex)
    elif n_points == 1:
        X_agg = np.zeros([n_ants, n_samps], dtype=complex)
        
    # Read/generate data, perform FFT and aggregate sensor data 
    for i in range(0, n_ants):
        full_filename[i] = filepath + filename + str(i) + extension
        # Read or generate complex data
        x = complex_data_sc16(data_flag, freq, tbin, full_filename[i], rx[i], ry[i], rz[i])
        if n_points > 1:
            # Perform FFT
            Xfft = perform_FFT(x, n_points)
            # Aggregate sensor data
            X_agg[i,:,:] = Xfft
        elif n_points == 1:
            # Aggregate sensor data
            X_agg[i,:] = x
    
    az_range = np.linspace(min_az, max_az,deg_range) # Range of azimuth
    el = center_el
    
    print(X_agg.shape)
    
    # Frequency of signal at narrowband frequency channel
    if n_points > 1:
        f = center_freq + (chan_idx[0]-n_points/2)*coarse_chan
    elif n_points == 1:
        chan_idx = 0
        f = center_freq
    
    R_x = np.zeros([n_ants, n_ants], dtype=complex)
    a = np.zeros([n_ants,1], dtype=complex)
    a_H = np.zeros([1,n_ants], dtype=complex)
    #Un = np.zeros([n_ants,1], dtype=complex)
    Un = np.zeros([n_ants,(n_ants-n_sources)])
    beam_el = center_el
    beam_az = center_az
    mix_down = 0
    a_center = array_manifold_vector(beam_el, beam_az, rx, ry, rz, f, n_ants, mix_down, 0)
    a_second = array_manifold_vector(beam_el+ang_spread_el, beam_az+ang_spread_az, rx, ry, rz, f, n_ants, mix_down, 0)
    P = np.zeros([n_ants,n_ants], dtype=complex)
    Ld = np.zeros([deg_range,n_points])
    ld = np.zeros([deg_range,n_points])
    conventional_beamformer_result = np.zeros([deg_range,n_points])
    P_est = np.zeros([deg_range,n_points])
    synth_image = np.zeros([deg_range,n_points])
    music_result = np.zeros([deg_range,n_points])
    max_mle_angle = np.zeros([n_points,1])
    max_mvdr_angle = np.zeros([n_points,1])
    max_conventional_beamformer_angle = np.zeros([n_points,1])
    max_music_angle = np.zeros([n_points,1])
    max_synth_angle = np.zeros([n_points,1])
    ld_normalized = np.zeros([deg_range,n_points])
    mvdr_normalized = np.zeros([deg_range,n_points])
    conventional_beamformer_normalized = np.zeros([deg_range,n_points])
    music_normalized = np.zeros([deg_range,n_points])
    synth_normalized = np.zeros([deg_range,n_points])
    spectra = np.zeros([n_points,1])
    synthesized_beam = np.zeros([deg_range,n_points])
    #synthesized_beam1 = np.zeros([deg_range,1])
    
    print("center_frequency = " + str(center_freq) + " f = " + str(f))
    
    print("Estimating power spectrum...")
    
    full_spectrum = 0 # 0 -> Don't save or plot full spectrum to save computation time
                      # 1 -> Plot 3 bins surrounding the one with the signal to save computation time
                      # 2 -> Plot full spectrum
    if full_spectrum == 0:
        freq_chan_indices = [chan_idx[0]]
    elif full_spectrum == 1:
        print("Minimum channel index = " + str(chan_idx[0]-1))
        print("Maximum channel index = " + str(chan_idx[0]+1))
        freq_chan_indices = range(chan_idx[0]-1, chan_idx[0]+2)
    elif full_spectrum == 2:
        display_bin = 0
        range_bins = 20
        freq_chan_indices = range(0, n_points)
    
    for ch in freq_chan_indices:
        if n_points > 1:
            f = center_freq + (ch-n_points/2)*coarse_chan
        elif n_points == 1:
            f = center_freq

        for az in range(0,deg_range):
            # Mix signal down
            X_shift = mix_signal_down(X_agg, az, el, rx, ry, rz, freq, ch, n_ants, n_samps)
    
            # Estimate sample covariance
            R_hat = estimate_sample_covariance(X_shift, n_ants, n_samps, n_points, n_ints)
    
            # Estimate visibilies (cross correlations)
            Vis = estimate_visibilities(X_shift, n_ants, n_samps)
    
            # Estimate auto-correlations
            Autos = estimate_auto_correlations(X_shift, n_ants, n_samps)

            R_x = R_hat[:,:,0]
            R_v = Vis[:,0]
            
            if full_spectrum==1 or full_spectrum==2:
                print("Frequency bin " + str(ch) + " of " + str(n_points))
                spectra[ch] = abs(np.matmul(np.matmul(np.ones([1,n_ants]),R_x),np.ones([n_ants,1])))
                if full_spectrum == 2:
                    if ch == (display_bin*range_bins):
                        print("Frequency bin " + str(ch) + " of " + str(n_points))
                        display_bin += 1
        
            eigenvalues,eigenvectors = np.linalg.eig(R_x)
            if n_sources == 1:
                largest_eigenvalue_idx = np.argmax(eigenvalues)
                #print("Largest eigenvalue idx = " + str(abs(largest_eigenvalue_idx)))
                eigenvectors_noise = np.delete(eigenvectors,largest_eigenvalue_idx,1)
                #print("Eigenvector shape = " + str(eigenvectors_noise.shape))
                Un = eigenvectors_noise # Eigenvector corresponding to the largest eigenvalue
            if n_sources == 2:
                #ordered_eigenvalues = np.argsort(eigenvalues, axis=0)
                #largest_eigenvalue_idx = np.argmax(ordered_eigenvalues[::-1])
                largest_eigenvalue_idx = np.argmax(eigenvalues)
                remaining_eigenvalues = np.delete(eigenvalues,largest_eigenvalue_idx,0)
                #print(abs(eigenvalues))
                #print(eigenvalues.shape)
                #print(abs(remaining_eigenvalues))
                #print(remaining_eigenvalues.shape)
                second_largest_eigenvalue_idx = np.argmax(abs(remaining_eigenvalues))
                #print("Largest eigenvalue idx = " + str(abs(largest_eigenvalue_idx)))
                #print("Second largest eigenvalue idx = " + str((second_largest_eigenvalue_idx+1)))
                eigenvectors_noise = np.delete(eigenvectors,[largest_eigenvalue_idx,(second_largest_eigenvalue_idx+1)],1)
                #print("Eigenvector shape = " + str(eigenvectors_noise.shape))
                Un = eigenvectors_noise # Eigenvector corresponding to the largest eigenvalue

            #a = array_manifold_vector(el, az, rx, ry, rz, f, n_ants)
            a = array_manifold_vector(el, az_range[az], rx, ry, rz, f, n_ants, 0, 0)
            a_H = np.transpose(np.conjugate(a))
            a_center_H = np.transpose(np.conjugate(a_center))
            a_second_H = np.transpose(np.conjugate(a_second))
            a_H_a = np.matmul(a_H,a)
            A_pinv = (1/a_H_a)*a_H
            P = np.matmul(a,A_pinv)
            P_perp = np.eye(n_ants,n_ants) - P
            # Maximum Likelihood
            Ld[az,ch] = -1*np.log(np.trace(abs(np.matmul(P_perp,R_x))))
            ld[az,ch] = np.trace(abs(np.matmul(P_perp,R_x)))
            # MVDR
            P_den = abs(np.dot(np.dot(a_H,np.linalg.inv(R_x)), a))
            P_est[az,ch] = 1/P_den
            # Conventional Beamformer
            conventional_beamformer_numerator = abs(np.matmul(np.matmul(a_H, R_x),a))
            conventional_beamformer_result[az,ch] = conventional_beamformer_numerator[0][0]/abs(a_H_a[0][0])
            # MUSIC
            U_H = np.transpose(np.conjugate(Un))
            music_denominator = abs(np.dot(np.dot(np.dot(a_H,Un),U_H),a))
            music_result[az,ch] = 1/music_denominator[0][0]
            # Synthesis Imaging
            v = interferometric_phase_shift(el, az_range[az], rx, ry, rz, f, n_ants)
            synth_image[az,ch] = abs(np.dot(R_v, v))
            
            beam_coordinate = np.matmul(a_center_H, a)[0]
            synthesized_beam[az,ch] = np.square(abs(beam_coordinate[0]))
            #beam_coordinate1 = np.matmul(a_second_H, a)[0]
            #synthesized_beam1[az,0] = np.square(abs(beam_coordinate1[0]))
            #P_den = abs(a_H.dot(np.linalg.inv(R_x)).dot(a))
            #P_den = abs(a_H.dot(np.linalg.inv(np.eye(n_ants,n_ants))).dot(a))
            #P_den = abs(np.dot(np.dot(a_H,np.linalg.inv(R_x)), a))
            #P[el,az] = 1/P_den
        
        # Normalize MLE result
        max_mle = np.max(1/ld[:,ch])
        ld_normalized[:,ch] = (1/max_mle)*(1/ld[:,ch])
        # Normalize MVDR result
        max_mvdr = np.max(P_est[:,ch])
        mvdr_normalized[:,ch] = (1/max_mvdr)*P_est[:,ch]
        # Normalize Conventional Beamformer result
        max_conventional_beamformer = np.max(conventional_beamformer_result[:,ch])
        conventional_beamformer_normalized[:,ch] = (1/max_conventional_beamformer)*conventional_beamformer_result[:,ch]
        # Normalize MUSIC result
        max_music = np.max(music_result[:,ch])
        music_normalized[:,ch] = (1/max_music)*(music_result[:,ch])
        # Normalize synthesized image result
        max_synth = np.max(synth_image[:,ch])
        synth_normalized[:,ch] = (1/max_synth)*(synth_image[:,ch])
        
        # Find max result index and angle of max result
        max_mle_idx = np.argmax(ld_normalized[:,ch])
        max_mle_angle[ch] = az_range[max_mle_idx]*np.pi/180
        max_mvdr_idx = np.argmax(mvdr_normalized[:,ch])
        max_mvdr_angle[ch] = az_range[max_mvdr_idx]*np.pi/180
        max_conventional_beamformer_idx = np.argmax(conventional_beamformer_normalized[:,ch])
        max_conventional_beamformer_angle[ch] = az_range[max_conventional_beamformer_idx]*np.pi/180
        max_music_idx = np.argmax(music_normalized[:,ch])
        max_music_angle[ch] = az_range[max_music_idx]*np.pi/180
        max_synth_idx = np.argmax(synth_normalized[:,ch])
        max_synth_angle[ch] = az_range[max_synth_idx]*np.pi/180

    print("Plotting...")
    # Plot the synthesized beam
    plt.figure()
    plt.plot(az_range, synthesized_beam[0:deg_range,chan_idx[0]])
    plt.title("Synthesized beam (dirty beam) over elevation at " + str(narrowband_freqs[chan_idx[0]][0]/1e6) + " MHz")
    plt.ylabel("Power (arb. units)")
    plt.xlabel("Azimuth (degrees)")
    plt.show()

    plt.figure()
    plt.plot(az_range, ld_normalized[0:deg_range,chan_idx[0]], label='MLE')
    plt.plot(az_range, mvdr_normalized[0:deg_range,chan_idx[0]], label='MVDR')
    plt.plot(az_range, conventional_beamformer_normalized[0:deg_range,chan_idx[0]], label='CONV-BF')
    plt.plot(az_range, music_normalized[0:deg_range,chan_idx[0]], label='MUSIC')
    plt.plot(az_range, synth_normalized[0:deg_range,chan_idx[0]], label='SYNTH IMG')
    plt.title("MLE, MVDR, CONV-BF, MUSIC, and SYNTH IMG estimate along the horizon at " + str(narrowband_freqs[chan_idx[0]][0]/1e6) + " MHz")
    plt.ylabel("Power (Normalized)")
    plt.xlabel("Azimuth (degrees)")
    plt.legend()
    plt.show()
    
    az_theta = np.linspace(0,2*np.pi, deg_range)
    plt.figure()
    plt.polar(az_theta, ld_normalized[0:deg_range,chan_idx[0]], label='MLE')
    plt.polar(az_theta, mvdr_normalized[0:deg_range,chan_idx[0]], label='MVDR')
    plt.polar(az_theta, conventional_beamformer_normalized[0:deg_range,chan_idx[0]], label='CONV-BF')
    plt.polar(az_theta, music_normalized[0:deg_range,chan_idx[0]], label='MUSIC')
    plt.polar(az_theta, synth_normalized[0:deg_range,chan_idx[0]], label='SYNTH IMG')
    plt.title("MLE, MVDR, CONV-BF, MUSIC, and SYNTH IMG estimate along the horizon at " + str(narrowband_freqs[chan_idx[0]][0]/1e6) + " MHz")
    plt.ylabel("Power (Normalized)")
    plt.xlabel("Azimuth (degrees)")
    plt.legend(loc='upper left')
    plt.show()
    
    # Plot array positions
    rfi_radius = 1000
    array_radius = 700
    axis_limit = 1200
    plt.figure()
    plt.plot(rfi_radius*np.cos(max_mle_angle[chan_idx[0]]),rfi_radius*np.sin(max_mle_angle[chan_idx[0]]), 'ro', label='MLE - '+str(np.round(max_mle_angle[chan_idx[0]][0]*180/np.pi))+'$^\circ$')
    plt.plot(rfi_radius*np.cos(max_mvdr_angle[chan_idx[0]]),rfi_radius*np.sin(max_mvdr_angle[chan_idx[0]]), 'bo', label='MVDR - '+str(np.round(max_mvdr_angle[chan_idx[0]][0]*180/np.pi))+'$^\circ$')
    plt.plot(rfi_radius*np.cos(max_conventional_beamformer_angle[chan_idx[0]]),rfi_radius*np.sin(max_conventional_beamformer_angle[chan_idx[0]]), 'yo', label='CONVBF - '+str(np.round(max_conventional_beamformer_angle[chan_idx[0]][0]*180/np.pi))+'$^\circ$')
    plt.plot(rfi_radius*np.cos(max_music_angle[chan_idx[0]]),rfi_radius*np.sin(max_music_angle[chan_idx[0]]), 'mo', label='MUSIC - '+str(np.round(max_music_angle[chan_idx[0]][0]*180/np.pi))+'$^\circ$')
    plt.plot(rfi_radius*np.cos(max_synth_angle[chan_idx[0]]),rfi_radius*np.sin(max_synth_angle[chan_idx[0]]), 'ko', label='SYNTH - '+str(np.round(max_synth_angle[chan_idx[0]][0]*180/np.pi))+'$^\circ$')
    plt.text(rfi_radius*np.cos(max_music_angle[chan_idx[0]]),rfi_radius*np.sin(max_music_angle[chan_idx[0]]), str(round(max_music_angle[chan_idx[0]][0]*180/np.pi))+'$^\circ$', horizontalalignment='right')
    plt.text(rfi_radius, 0, '0$^\circ$')
    plt.plot(array_radius*np.cos(az_theta),array_radius*np.sin(az_theta), 'g--')
    plt.plot(rx, ry, 'g1')
    plt.xlim(-1*axis_limit,axis_limit)
    plt.ylim(-1*axis_limit,axis_limit)
    plt.title("MLE, MVDR, CONV-BF, MUSIC, and SYNTH DOA estimate along the horizon of array at " + str(narrowband_freqs[chan_idx[0]][0]/1e6) + " MHz")
    plt.xlabel("Antenna Positions East to West")
    plt.ylabel("Antenna Positions North to South")
    plt.yticks([])
    plt.xticks([])
    #plt.legend(bbox_to_anchor=(1.04,0.5),loc='center left') # Outside of plot
    plt.legend(loc='upper right')
    plt.show()
    
    if full_spectrum == 1:
        if n_points > 1:
            plt.figure()
            plt.plot(narrowband_freqs[(chan_idx[0]-1):(chan_idx[0]+2)]/1e6, spectra[(chan_idx[0]-1):(chan_idx[0]+2)])
            plt.title("Average spectra over the sensor array")
            plt.ylabel("Power (arb. units)")
            plt.xlabel("Frequency (MHz)")
            plt.show()
    if full_spectrum == 2:
        if n_points > 1:
            plt.figure()
            plt.plot(narrowband_freqs/1e6, spectra)
            plt.title("Average spectra over the sensor array")
            plt.ylabel("Power (arb. units)")
            plt.xlabel("Frequency (MHz)")
            plt.show()

    end_time = time.time()
    execution_time = end_time-start_time
    print("Execution time = " + str(execution_time) + " seconds")
    print("Done!")


if __name__ == "__main__":
    main()





